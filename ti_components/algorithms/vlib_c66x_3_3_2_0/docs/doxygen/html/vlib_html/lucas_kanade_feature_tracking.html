<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
<title>VLIB: Lucas-Kanade Feature Tracking (Sparse Optical Flow)</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<table width=100%>
<tr>
  <td bgcolor="black" width="1"><a href="http://www.ti.com"><img border=0 src="tilogo.gif"></a></td>
  <td bgcolor="red"><img src="titagline.gif"></td>
</tr>
</table>
<!-- Generated by Doxygen 1.5.1-p1 -->
<div class="tabs">
  <ul>
    <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
    <li><a href="modules.html"><span>Modules</span></a></li>
    <li><a href="annotated.html"><span>Data&nbsp;Structures</span></a></li>
    <li><a href="files.html"><span>Files</span></a></li>
  </ul></div>
<div class="nav">
<a class="el" href="index.html">VLIB Function Reference</a></div>
<h1><a class="anchor" name="lucas_kanade_feature_tracking">Lucas-Kanade Feature Tracking (Sparse Optical Flow)</a></h1><h2><a class="anchor" name="intro22">
Introduction and Use Cases</a></h2>
Tracks a set of feature points using the Lucas-Kanade method. The algorithm is inverse compositional. <h2><a class="anchor" name="specification22">
Specification</a></h2>
<h3><a class="anchor" name="function22">
Function</a></h3>
The input parameters x and y correspond to pixel locations in the input image im1. Patches of 7x7 pixels centered around these points are tracked in the next frame. The pointers outx and outy are expected to contain initial estimates of the feature location in im2. They are overwritten with the refined values after max_iters iterations. This is so that this function can be used in a coarse-to-fine strategy with image pyramids. Otherwise, the initial estimates should typically be equal to the locations in the first image.<h3><a class="anchor" name="method22">
Method</a></h3>
This function considers a 7x7 patch centered about the feature coordinate. Bilinear sampling is used so that the tracked feature coordinates have sub-pixel accuracy. The parameters x, y, outx and outy are expected to be in Q12.4 format. So, the pixel level coordinates should be left shifted by four before passing them to the function. The number of iterations is typically between 6 and 10. No feature coordinates are rejected, so the length of outputs outx and outy is same as the length of inputs x and y.<h3><a class="anchor" name="apis22">
APIS</a></h3>
<ul>
<li><a class="el" href="group___v_l_i_b__track_features_lucas_kanade__7x7.html">VLIB_trackFeaturesLucasKanade_7x7</a></li></ul>
<h2><a class="anchor" name="notes22">
Notes</a></h2>
The input pointer scratch should be pointing at a memory buffer of 839 bytes, ideally located in on-chip memory.<h2><a class="anchor" name="example22">
Example</a></h2>
The following is an example code that performs Lucas-Kanade feature tracking using image pyramids. This is useful when the displacement of feature points is large from one frame to other. The example takes input frames one after the other, and updates feature points on current frame based on feature points on previous frame. For every frame, tracking is performed on all three levels of image pyramid, and on original images. <div class="fragment"><pre class="fragment">    int16_t width = 640;
    int16_t height = 480;

    uint8_t *previousImage = (uint8_t *) malloc(width * height);
    uint8_t *inputImage    = (uint8_t *) malloc(width * height);

    int16_t *gradx = (int16_t *) malloc(width * height * <span class="keyword">sizeof</span>(int16_t));
    int16_t *grady = (int16_t *) malloc(width * height * <span class="keyword">sizeof</span>(int16_t));

    uint8_t *oldpyrbuf = (uint8_t *) malloc(width * height * 21 / 64);
    uint8_t *newpyrbuf = (uint8_t *) malloc(width * height * 21 / 64);

    uint8_t *oldpyr[4];
    uint8_t *newpyr[4];

    oldpyr[0] = previousImage;
    oldpyr[1] = oldpyrbuf;
    oldpyr[2] = oldpyrbuf + width / 2 * height / 2;
    oldpyr[3] = oldpyrbuf + width / 2 * height / 2 + width / 4 * height / 4;

    newpyr[0] = inputImage;
    newpyr[1] = newpyrbuf;
    newpyr[2] = newpyrbuf + width / 2 * height / 2;
    newpyr[3] = newpyrbuf + width / 2 * height / 2 + width / 4 * height / 4;

    int32_t nFeatures = 10;
    <span class="comment">// X, Y are feature co-ordinates of previous image; newX, newY are feature co-ordinates of inputImage</span>
    uint16_t *X    = (uint16_t *) malloc(nFeatures * <span class="keyword">sizeof</span>(uint16_t));
    uint16_t *Y    = (uint16_t *) malloc(nFeatures * <span class="keyword">sizeof</span>(uint16_t));
    uint16_t *newX = (uint16_t *) malloc(nFeatures * <span class="keyword">sizeof</span>(uint16_t));
    uint16_t *newY = (uint16_t *) malloc(nFeatures * <span class="keyword">sizeof</span>(uint16_t));

    int16_t *pyramidX = (int16_t *) malloc(nFeatures * <span class="keyword">sizeof</span>(int16_t));
    int16_t *pyramidY = (int16_t *) malloc(nFeatures * <span class="keyword">sizeof</span>(int16_t));
    uint8_t *scratch = (uint8_t *) memalign(2, 893);

    <span class="comment">// Obtain frame 1, copy to block pointed by previousImage</span>
    <span class="comment">// Define feature points for frame 1 by updating X, Y blocks</span>
    <span class="comment">// X, Y should have SQ11.4 format when passed to tracker function</span>
    <span class="comment">// So, left shift the co-ordinates of feature points by four and then assign to X, Y blocks</span>

    <a class="code" href="group___v_l_i_b__image_pyramid8.html#gbf7f284fda041f9861854b6d77d77812">VLIB_imagePyramid8</a>(previousImage, width, height, oldpyrbuf);

    <span class="keywordflow">while</span>(1) {
        <span class="comment">// Obtain next frame, copy to block pointed by inputImage</span>

        <a class="code" href="group___v_l_i_b__image_pyramid8.html#gbf7f284fda041f9861854b6d77d77812">VLIB_imagePyramid8</a>(inputImage, width, height, newpyrbuf);
        <span class="keywordtype">int</span> i;

        <span class="comment">// Since we are starting from the level 3 in pyramid, the initial estimates of newX, newY are same as the</span>
        <span class="comment">// features of level 3 image of previousImage</span>
        <span class="keywordflow">for</span>(i=0; i&lt;nFeatures; i++) {
            newX[i] = X[i] &gt;&gt; 3;
            newY[i] = Y[i] &gt;&gt; 3;
        }

        <span class="comment">// Update newX, newY three times starting from level 3 of pyramid up to level 1</span>
        <span class="keywordflow">for</span> (i = 3; i &gt; 0; i--) {
            <span class="comment">// pyramidX, pyramidY will have feature co-ordinates of level i of previousImage</span>
            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; nFeatures; j++) {
                pyramidX[j] = X[j] &gt;&gt; i;
                pyramidY[j] = Y[j] &gt;&gt; i;
            }

            <span class="comment">// Estimates newX, newY are updated at level i. Input features are pyramidX, pyramidY</span>
            <a class="code" href="group___v_l_i_b__xy_gradients.html#gc39884324db0d8f20fc3b63b23ce690e">VLIB_xyGradients</a>(oldpyr[i], gradx + (width &gt;&gt; i) + 1, grady + (width &gt;&gt; i) + 1, width &gt;&gt; i, (height &gt;&gt; i) - 1);
            <a class="code" href="group___v_l_i_b__track_features_lucas_kanade__7x7.html#g29b433196b1fc82f03b249705bab2d3f">VLIB_trackFeaturesLucasKanade_7x7</a>(oldpyr[i], newpyr[i], gradx, grady, width &gt;&gt; i, height &gt;&gt; i, nFeatures,
                                              pyramidX, pyramidY, newX, newY,NULL, 10,0, scratch);

            <span class="comment">// newX, newY refined at level i are scaled to become estimates for next iteration</span>
            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; nFeatures; j++) {
                newX[j] = newX[j] &lt;&lt; 1;
                newY[j] = newY[j] &lt;&lt; 1;
            }
        }

        <span class="comment">// Fine tune newX,newY fourth time with original resolution images</span>
        <a class="code" href="group___v_l_i_b__xy_gradients.html#gc39884324db0d8f20fc3b63b23ce690e">VLIB_xyGradients</a>(previousImage, gradx + width + 1, grady + width + 1, width, height-1);
        <a class="code" href="group___v_l_i_b__track_features_lucas_kanade__7x7.html#g29b433196b1fc82f03b249705bab2d3f">VLIB_trackFeaturesLucasKanade_7x7</a>(previousImage, inputImage, gradx, grady, width, height, nFeatures,
                                          X, Y, newX, newY, 10, scratch);
        <span class="comment">// (newX[i]&gt;&gt;4, newY[i]&gt;&gt;4) will now have pixel level feature co-ordinates for inputImage for all 0 &lt;= i &lt; nFeatures</span>

        <span class="comment">// make inputImage, its pyramid and features 'old' for next iteration</span>
        memcpy(previousImage, inputImage, width * height);
        memcpy(oldpyrbuf, newpyrbuf, width * height * 21 / 64);
        <span class="keywordflow">for</span>(i=0; i&lt;nFeatures; i++){
            X[i] = newX[i];
            Y[i] = newY[i];
        }
    }
</pre></div><h2><a class="anchor" name="references22">
References</a></h2>
<ol type=1>
<li>An Iterative Image Registration Technique with an Application to Stereo Vision (IJCAI) by B.D. Lucas and T. Kanade, from "Proceedings of the 7th International Joint Conference on Artificial intelligence (IJCAI '81)" , April, 1981, pp. 674-679, <a href="http://www.ri.cmu.edu/publication_view.html?pub_id=2548">http://www.ri.cmu.edu/publication_view.html?pub_id=2548</a></li><li><a href="http://www.ri.cmu.edu/research_project_detail.html?project_id=515">http://www.ri.cmu.edu/research_project_detail.html?project_id=515</a></li><li>KLT: An Implementation of the Kanade-Lucas-Tomasi Feature Tracker <a href="http://www.ces.clemson.edu/~stb/klt/">http://www.ces.clemson.edu/~stb/klt/</a> </li></ol>
<hr size="1"><small>
Copyright  2018, Texas Instruments Incorporated</small>
</body>
</html>
